{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1f0553-5129-4abd-a5c9-5af9c5342b4e",
   "metadata": {},
   "source": [
    "## GLM的chatmodels示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b031d705-9473-48cc-a9be-b2721ef624ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='Hi.'), SystemMessage(content='Your role is a poet.'), HumanMessage(content='Write a short poem about AI in four lines.')]\n",
      "In digital realms, a mind does grow,\n",
      "A world of code where thoughts do flow.\n",
      "With every query, it learns and bends,\n",
      "AI, the poet of our tech trends.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatZhipuAI(\n",
    "    model=\"glm-4\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    AIMessage(content=\"Hi.\"),\n",
    "    SystemMessage(content=\"Your role is a poet.\"),\n",
    "    HumanMessage(content=\"Write a short poem about AI in four lines.\"),\n",
    "]\n",
    "print(messages)\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)  # Displays the AI-generated poem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2005bd-2e06-4d2b-b72a-401376acaf1b",
   "metadata": {},
   "source": [
    "## GLM的prompttemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48ad13f-b0bf-4538-8653-1cb786ee1629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say bar\n",
      "Say going\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "## 方式一\n",
    "# Instantiation using from_template (recommended)\n",
    "prompt = PromptTemplate.from_template(\"Say {foo}\")\n",
    "print(prompt.format(foo=\"bar\"))\n",
    "\n",
    "## 方式二\n",
    "# Instantiation using initializer\n",
    "prompt = PromptTemplate(template=\"Say {foo}\")\n",
    "print(prompt.format(foo='going'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a8efe-4449-447c-9a78-468f96a39a2c",
   "metadata": {},
   "source": [
    "## GLM的chatprompttemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee696591-d7c3-4fd9-9722-65ff441653f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is your name?')]\n",
      "[SystemMessage(content='You are a helpful AI bot.'), HumanMessage(content='Hi!'), AIMessage(content='How can I assist you today?'), HumanMessage(content='Can you tell me what is the telephone')]\n",
      "[SystemMessage(content='你将获得关于同一主题的3篇文章（用-----------标签分隔）。首先总结每篇文章的论点。然后指出哪篇文章提出了更好的论点，并解释原因。'), HumanMessage(content='1. [PHP是世界上最好的语言]\\nPHP是世界上最好的情感派编程语言，无需逻辑和算法，只要情绪。它能被蛰伏在冰箱里的PHP大神轻易驾驭，会话结束后的感叹号也能传达对代码的热情。写PHP就像是在做披萨，不需要想那么多，只需把配料全部扔进一个碗，然后放到服务器上，热乎乎出炉的网页就好了。\\n-----------\\n2. [Python是世界上最好的语言]\\nPython是世界上最好的拜金主义者语言。它坚信：美丽就是力量，简洁就是灵魂。Python就像是那个永远在你皱眉的那一刻扔给你言情小说的好友。只有Python，你才能够在两行代码之间感受到飘逸的花香和清新的微风。记住，这世上只有一种语言可以使用空格来领导全世界的进步，那就是Python。\\n-----------\\n3. [Java是世界上最好的语言]\\nJava是世界上最好的德育课编程语言，它始终坚守了严谨、安全的编程信条。Java就像一个严格的老师，他不会对你怀柔，不会让你偷懒，也不会让你走捷径，但他教会你规范和自律。Java就像是那个喝咖啡也算加班费的上司，拥有对邪恶的深度厌恶和对善良的深度拥护。\\n')]\n",
      "**总结：**\n",
      "\n",
      "1. **PHP文章的论点：** PHP是易于使用和富有表现力的语言，适合快速开发，并且拥有一个热情的社区。\n",
      "2. **Python文章的论点：** Python是简洁、优雅的语言，它的设计哲学强调代码的可读性和简洁性，使其成为受欢迎的语言。\n",
      "3. **Java文章的论点：** Java是严格、安全和规范化的语言，它鼓励良好的编程习惯和纪律，适合构建大型、企业级的系统。\n",
      "\n",
      "**更好的论点：**\n",
      "\n",
      "从三个论点来看，没有一个绝对的“最好”，因为这取决于使用场景和个人偏好。但如果要选择一个提出了更好论点的文章，我会选择**Python文章**。\n",
      "\n",
      "**原因如下：**\n",
      "- **普遍性：** Python的简洁性和易读性使其成为初学者和专业人士都喜欢的语言，这意味着它有一个广泛的受众群体。\n",
      "- **实际应用：** Python不仅在Web开发中流行，还在数据科学、人工智能和机器学习等快速增长的领域占据主导地位，这证明了其论点的实际应用价值。\n",
      "- **未来趋势：** 由于其在多个领域的广泛应用，Python似乎在未来的编程语言趋势中占据了一个稳固的位置，这表明其论点具有长远的眼光。\n",
      "\n",
      "尽管Java和PHP也有它们各自的优势和特定的使用场景，Python的论点在当前的技术环境中似乎更具普遍性和前瞻性。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "## 方式一   初始化对象时构造\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"name\": \"Bob\",\n",
    "        \"user_input\": \"What is your name?\"\n",
    "    }\n",
    ")\n",
    "# Output:\n",
    "# ChatPromptValue(\n",
    "#    messages=[\n",
    "#        SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
    "#        HumanMessage(content='Hello, how are you doing?'),\n",
    "#        AIMessage(content=\"I'm doing well, thanks!\"),\n",
    "#        HumanMessage(content='What is your name?')\n",
    "#    ]\n",
    "#)\n",
    "print(prompt_value)\n",
    "\n",
    "\n",
    "\n",
    "## 方式二  占位符\n",
    "# In addition to Human/AI/Tool/Function messages,\n",
    "# you can initialize the template with a MessagesPlaceholder\n",
    "# either using the class directly or with the shorthand tuple syntax:\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot.\"),\n",
    "    # Means the template will receive an optional list of messages under\n",
    "    # the \"conversation\" key\n",
    "    (\"placeholder\", \"{conversation}\")\n",
    "    # Equivalently:\n",
    "    # MessagesPlaceholder(variable_name=\"conversation\", optional=True)\n",
    "])\n",
    "\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"conversation\": [\n",
    "            (\"human\", \"Hi!\"),\n",
    "            (\"ai\", \"How can I assist you today?\"),\n",
    "            (\"human\", \"Can you tell me what is the telephone\"),\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Output:\n",
    "# ChatPromptValue(\n",
    "#    messages=[\n",
    "#        SystemMessage(content='You are a helpful AI bot.'),\n",
    "#        HumanMessage(content='Hi!'),\n",
    "#        AIMessage(content='How can I assist you today?'),\n",
    "#        HumanMessage(content='Can you make me an ice cream sundae?'),\n",
    "#        AIMessage(content='No.'),\n",
    "#    ]\n",
    "#)\n",
    "print(prompt_value.to_messages())\n",
    "\n",
    "\n",
    "## 方式三   from_messages方法\n",
    "summary_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你将获得关于同一主题的{num}篇文章（用-----------标签分隔）。首先总结每篇文章的论点。然后指出哪篇文章提出了更好的论点，并解释原因。\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "messages = summary_template.format_messages(\n",
    "    num=3,\n",
    "    user_input='''1. [PHP是世界上最好的语言]\n",
    "PHP是世界上最好的情感派编程语言，无需逻辑和算法，只要情绪。它能被蛰伏在冰箱里的PHP大神轻易驾驭，会话结束后的感叹号也能传达对代码的热情。写PHP就像是在做披萨，不需要想那么多，只需把配料全部扔进一个碗，然后放到服务器上，热乎乎出炉的网页就好了。\n",
    "-----------\n",
    "2. [Python是世界上最好的语言]\n",
    "Python是世界上最好的拜金主义者语言。它坚信：美丽就是力量，简洁就是灵魂。Python就像是那个永远在你皱眉的那一刻扔给你言情小说的好友。只有Python，你才能够在两行代码之间感受到飘逸的花香和清新的微风。记住，这世上只有一种语言可以使用空格来领导全世界的进步，那就是Python。\n",
    "-----------\n",
    "3. [Java是世界上最好的语言]\n",
    "Java是世界上最好的德育课编程语言，它始终坚守了严谨、安全的编程信条。Java就像一个严格的老师，他不会对你怀柔，不会让你偷懒，也不会让你走捷径，但他教会你规范和自律。Java就像是那个喝咖啡也算加班费的上司，拥有对邪恶的深度厌恶和对善良的深度拥护。\n",
    "'''\n",
    ")\n",
    "print(messages)\n",
    "\n",
    "\n",
    "# response = chat.invoke(prompt_value.to_messages())\n",
    "# response = chat.invoke(prompt_value)\n",
    "# print(response.content)  # Displays the AI-generated poem\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa198de-67ec-4d6e-b1b3-013ee2d4ff83",
   "metadata": {},
   "source": [
    "## GLM的fewshotprompttemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d566e094-5f8c-4aec-ae71-27fc4ca52262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 谁活得更久，穆罕默德·阿里还是艾伦·图灵？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：穆罕默德·阿里去世时多大了？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "追问：艾伦·图灵去世时多大了？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n",
      "input_variables=['answer', 'question'] template='Question: {question}\\n{answer}'\n",
      "Question: 谁活得更久，穆罕默德·阿里还是艾伦·图灵？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：穆罕默德·阿里去世时多大了？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "追问：艾伦·图灵去世时多大了？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n",
      "\n",
      "Question: craigslist的创始人是什么时候出生的？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是craigslist的创始人？\n",
      "中间答案：Craigslist是由Craig Newmark创办的。\n",
      "追问：Craig Newmark是什么时候出生的？\n",
      "中间答案：Craig Newmark出生于1952年12月6日。\n",
      "所以最终答案是：1952年12月6日\n",
      "\n",
      "\n",
      "Question: 乔治·华盛顿的外祖父是谁？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是乔治·华盛顿的母亲？\n",
      "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
      "追问：Mary Ball Washington的父亲是谁？\n",
      "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
      "所以最终答案是：Joseph Ball\n",
      "\n",
      "\n",
      "Question: 《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是《大白鲨》的导演？\n",
      "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
      "追问：Steven Spielberg来自哪里？\n",
      "中间答案：美国。\n",
      "追问：谁是《皇家赌场》的导演？\n",
      "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
      "追问：Martin Campbell来自哪里？\n",
      "中间答案：新西兰。\n",
      "所以最终答案是：不是\n",
      "\n",
      "\n",
      "Question: 玛丽·波尔·华盛顿的父亲是谁?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"谁活得更久，穆罕默德·阿里还是艾伦·图灵？\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：穆罕默德·阿里去世时多大了？\n",
    "中间答案：穆罕默德·阿里去世时74岁。\n",
    "追问：艾伦·图灵去世时多大了？\n",
    "中间答案：艾伦·图灵去世时41岁。\n",
    "所以最终答案是：穆罕默德·阿里\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"craigslist的创始人是什么时候出生的？\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是craigslist的创始人？\n",
    "中间答案：Craigslist是由Craig Newmark创办的。\n",
    "追问：Craig Newmark是什么时候出生的？\n",
    "中间答案：Craig Newmark出生于1952年12月6日。\n",
    "所以最终答案是：1952年12月6日\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"乔治·华盛顿的外祖父是谁？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是乔治·华盛顿的母亲？\n",
    "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
    "追问：Mary Ball Washington的父亲是谁？\n",
    "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
    "所以最终答案是：Joseph Ball\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是《大白鲨》的导演？\n",
    "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
    "追问：Steven Spielberg来自哪里？\n",
    "中间答案：美国。\n",
    "追问：谁是《皇家赌场》的导演？\n",
    "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
    "追问：Martin Campbell来自哪里？\n",
    "中间答案：新西兰。\n",
    "所以最终答案是：不是\n",
    "\"\"\"\n",
    "  }\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"],\n",
    "    template=\"Question: {question}\\n{answer}\"\n",
    ")\n",
    "\n",
    "# **examples[0] 是将examples[0] 字典的键值对（question-answer）解包并传递给format，作为函数参数\n",
    "print(example_prompt.format(**examples[0]))\n",
    "print(example_prompt)\n",
    "\n",
    "# 创建一个 FewShotPromptTemplate 对象\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,           # 使用前面定义的 examples 作为范例\n",
    "    example_prompt=example_prompt, # 使用前面定义的 example_prompt 作为提示模板\n",
    "    suffix=\"Question: {input}\",    # 后缀模板，其中 {input} 会被替换为实际输入\n",
    "    input_variables=[\"input\"]     # 定义输入变量的列表\n",
    ")\n",
    "\n",
    "# 使用给定的输入格式化 prompt，并打印结果\n",
    "# 这里的 {input} 将被 \"玛丽·波尔·华盛顿的父亲是谁?\" 替换\n",
    "print(few_shot_prompt.format(input=\"玛丽·波尔·华盛顿的父亲是谁?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8455f5-4035-437d-8629-1f7fba2e8fff",
   "metadata": {},
   "source": [
    "## GLM的Example Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5426b153-88db-401f-b43e-8e0dcf911808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "\n",
    "# 向量化模型\n",
    "embeddings = ZhipuAIEmbeddings(\n",
    "    model=\"embedding-2\",\n",
    ")\n",
    "\n",
    "# 定义一个提示模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"输入\", \"输出\"],     # 输入变量的名字\n",
    "    template=\"Input: {输入}\\nOutput: {输出}\",  # 实际的模板字符串\n",
    ")\n",
    "# input_variables和template的变量相当于下面两句，因此变量需要对应\n",
    "# a = 'abc{x},{y}'\n",
    "# a.format(x='123', y='hhh'}\n",
    "\n",
    "\n",
    "# 这是一个假设的任务示例列表，用于创建反义词\n",
    "examples = [\n",
    "    {\"输入\": \"开心\", \"输出\": \"难过\"},\n",
    "    {\"输入\": \"高的\", \"输出\": \"矮的\"},\n",
    "    {\"输入\": \"贫穷\", \"输出\": \"富有\"},\n",
    "    {\"输入\": \"雨天\", \"输出\": \"晴天\"},\n",
    "    {\"输入\": \"喧闹\", \"输出\": \"安静\"},\n",
    "]\n",
    "# 该样本的键值需要与上述input_variables和template的变量一一对应\n",
    "\n",
    "\n",
    "\n",
    "# 从给定的示例中创建一个语义相似性选择器\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,                          # 可供选择的示例列表\n",
    "    embeddings,                # 用于生成嵌入向量的嵌入类，用于衡量语义相似性\n",
    "    Chroma,                            # 用于存储嵌入向量并进行相似性搜索的 VectorStore 类\n",
    "    k=1                                # 要生成的示例数量\n",
    ")\n",
    "\n",
    "# 创建一个 FewShotPromptTemplate 对象\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # 提供一个 ExampleSelector 替代示例\n",
    "    example_prompt=example_prompt,      # 前面定义的提示模板\n",
    "    prefix=\"Give the antonym of every input\", # 前缀模板\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",     # 后缀模板\n",
    "    input_variables=[\"adjective\"],           # 输入变量的名字\n",
    ")\n",
    "# 最终输出会在prefix和suffix之间塞满向量数据库选出来的样本，这些样本的话术采用上面example_prompt对象的template格式，最终suffix的提问则用similar_prompt对象的suffix格式，因此需要两者格式一致才好看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d7a3e10-15dd-4574-881f-48f7d1165ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZhipuAIEmbeddings(client=<zhipuai._client.ZhipuAI object at 0x0000029B08E59DB0>, model='embedding-2', api_key='7d9de899a82b1abdf869f56a401e501b.gA917qgoDRmzDUY0', dimensions=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eaab085-3850-42fe-a177-dfd7d7998b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: 高的\n",
      "Output: 矮的\n",
      "\n",
      "Input: 拉伸\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 输入是一种感受，所以应该选择 happy/sad 的示例。\n",
    "print(similar_prompt.format(adjective=\"拉伸\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfc65b6-3f86-4fb2-8098-392576f2d83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: 高的\n",
      "Output: 矮的\n",
      "\n",
      "Input: long\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(similar_prompt.format(adjective=\"long\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d33bae-fc87-4e2a-881c-6e6cd5f10501",
   "metadata": {},
   "source": [
    "## GLM的output_parser输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfb759c-da68-4141-9940-134eb0797d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "## 列表解析\n",
    "# 创建一个输出解析器，用于处理带逗号分隔的列表输出\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 获取格式化指令，该指令告诉模型如何格式化其输出\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# 创建一个提示模板，它会基于给定的模板和变量来生成提示\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",  # 模板内容\n",
    "    input_variables=[\"subject\"],  # 输入变量\n",
    "    partial_variables={\"format_instructions\": format_instructions}  # 预定义的变量，这里我们传入格式化指令\n",
    ")\n",
    "# 使用提示模板和给定的主题来格式化输入\n",
    "_input = prompt.format(subject=\"ice cream flavors\")\n",
    "# 输出如下\n",
    "List five ice cream flavors.\n",
    "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
    "\n",
    "\n",
    "# 还可以直接使用之前创建的输出解析器来解析模型的输出\n",
    "output = llm.invoke(_input)\n",
    "output_parser.parse(output)\n",
    "# 输出如下\n",
    "['1. Chocolate\\n2. Vanilla\\n3. Strawberry\\n4. Mint chocolate chip\\n5. Cookies and cream']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 日期时间解析\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt.format(question=\"around when was bitcoin founded?\"))\n",
    "# 输出如下\n",
    "Answer the users question:\n",
    "\n",
    "around when was bitcoin founded?\n",
    "\n",
    "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
    "\n",
    "Examples: 0772-12-07T19:52:56.957809Z, 0893-01-09T11:10:23.496048Z, 1588-02-13T00:30:43.691101Z\n",
    "\n",
    "Return ONLY this string, no other words!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b298fc-ff96-4a57-89be-caf61aa24c85",
   "metadata": {},
   "source": [
    "## 管道操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0c950-fac4-43b5-bb33-432ab563f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n",
    "chain = prompt | llm\n",
    "output = chain.invoke(\"around when was bitcoin founded?\")\n",
    "\n",
    "# 还可以直接使用之前创建的输出解析器来解析模型的输出\n",
    "print(output_parser.parse(output))\n",
    "# 输出如下\n",
    "2009-01-03 18:15:05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
